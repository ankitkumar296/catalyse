{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 22:47:10.159397: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-30 22:47:10.162195: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-30 22:47:10.192478: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 22:47:10.664620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "# from tensorflowkeras.utils.vis_utils import plot_model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import ndimage\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization,Conv2D,MaxPooling2D,Activation,Dropout,Lambda,Dense,Flatten,Input\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 32, 32, 3), dtype=float32, sparse=None, name=keras_tensor>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input((32, 32, 3))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_MTL():\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        self.layer_list=[]\n",
    "        x_shape, y_angle_shape, y_cifar10_shape=(50000, 32, 32, 3), (50000, 4), (50000, 10)\n",
    "        angle_classifier_no=4\n",
    "        cifar10_classifier_no=10\n",
    "        inputs = keras.Input((32, 32, 3))\n",
    "        conv_base = self.get_convbase(inputs)\n",
    "        angle_classifier = self.get_classifier(conv_base, angle_classifier_no, \"angle\",count=15)\n",
    "        cifar10_classifier = self.get_classifier(conv_base, cifar10_classifier_no, \"cifar10\",count=22)\n",
    "        self.model = Model(\n",
    "            inputs=inputs, \n",
    "            outputs=[cifar10_classifier, angle_classifier]\n",
    "        )\n",
    "        tf.keras.utils.plot_model(self.model, to_file='final_mtl_model.png', show_shapes=True,show_layer_names=True)\n",
    "    \n",
    "   \n",
    "    def get_convbase(self,inputs):\n",
    "    \n",
    "    # reg = keras.regularizers.l2(1e-4)\n",
    "    \n",
    "    # initializer = keras.initializers.HeNormal()\n",
    "\n",
    "\n",
    "        x = Conv2D(16, (3, 3), padding=\"same\",name='1_conv2D_1')(inputs)\n",
    "        x = Activation(\"relu\",name='2_activation_1')(x)\n",
    "        x = BatchNormalization(axis=-1,name='3_batch_norm_1')(x)\n",
    "        x = MaxPooling2D(pool_size=(3, 3),name='4_maxPool_1')(x)\n",
    "        x = Dropout(0.25,name='5_dropout_1')(x)\n",
    "        \n",
    "        x = Conv2D(32, (3, 3), padding=\"same\",name='6_conv2D_2')(x)\n",
    "        x = Activation(\"relu\",name='7_activation_2')(x)\n",
    "        x = BatchNormalization(axis=-1,name='8_batch_norm_2')(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2),name='9_maxPool_2')(x)\n",
    "        x = Dropout(0.25,name='10_dropout_2')(x)\n",
    "        \n",
    "        x = Conv2D(32, (3, 3), padding=\"same\",name='11_conv2D_3')(x)\n",
    "        x = Activation(\"relu\",name='12_activation_3')(x)\n",
    "        x = BatchNormalization(axis=-1,name='13_batch_norm_3')(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2),name='14_maxPool_3')(x)\n",
    "        x = Dropout(0.25,name='15_dropout_3')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_classifier(self,x, class_no, name,count):\n",
    "    \n",
    "        x = Flatten(name=f'{count+1}_layer')(x)\n",
    "        x = Dense(128,name=f'{count+2}_layer')(x)\n",
    "        x = Activation(\"relu\",name=f'{count+3}_layer')(x)\n",
    "        x = BatchNormalization(name=f'{count+4}_layer')(x)\n",
    "        x = Dropout(0.5,name=f'{count+5}_layer')(x)\n",
    "        x = Dense(class_no,name=f'{count+6}_layer')(x)\n",
    "        x = Activation(\"softmax\", name=name)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def load_weights(self):\n",
    "        self.model.load_weights('./custom_mtl_model.h5')\n",
    "        \n",
    "    def execute_predict(self,input_data):\n",
    "        st1=time.perf_counter()\n",
    "        out=self.model.predict(input_data)\n",
    "        et1=time.perf_counter()\n",
    "        el1=et1-st1\n",
    "        print(f'Elapsed Time: {el1}')\n",
    "        return out\n",
    "    \n",
    "    def print_lays(self):\n",
    "        for lay in self.model.layers:\n",
    "            self.layer_list.append(lay)\n",
    "            print(lay)\n",
    "    def execute_lbl(self,input_data):\n",
    "        st2=time.perf_counter()\n",
    "        out=buffer=input_data\n",
    "        for idx in range(1,len(self.model.layers)):\n",
    "            print(f'Executing: {self.model.layers[idx]}')\n",
    "            if idx <= 15:\n",
    "                out=buffer=self.model.layers[idx](out)\n",
    "            elif idx in [16,18,20,22,24,26,28]:\n",
    "                out=self.model.layers[idx](out)\n",
    "            elif idx in [17,19,21,23,25,27,29]:\n",
    "                buffer=self.model.layers[idx](buffer)\n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(f'Elapsed Time: {el2}')\n",
    "        return out,buffer\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.rand(1,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<InputLayer name=input_layer_7, built=True>\n",
      "<Conv2D name=1_conv2D_1, built=True>\n",
      "<Activation name=2_activation_1, built=True>\n",
      "<BatchNormalization name=3_batch_norm_1, built=True>\n",
      "<MaxPooling2D name=4_maxPool_1, built=True>\n",
      "<Dropout name=5_dropout_1, built=True>\n",
      "<Conv2D name=6_conv2D_2, built=True>\n",
      "<Activation name=7_activation_2, built=True>\n",
      "<BatchNormalization name=8_batch_norm_2, built=True>\n",
      "<MaxPooling2D name=9_maxPool_2, built=True>\n",
      "<Dropout name=10_dropout_2, built=True>\n",
      "<Conv2D name=11_conv2D_3, built=True>\n",
      "<Activation name=12_activation_3, built=True>\n",
      "<BatchNormalization name=13_batch_norm_3, built=True>\n",
      "<MaxPooling2D name=14_maxPool_3, built=True>\n",
      "<Dropout name=15_dropout_3, built=True>\n",
      "<Flatten name=23_layer, built=True>\n",
      "<Flatten name=16_layer, built=True>\n",
      "<Dense name=24_layer, built=True>\n",
      "<Dense name=17_layer, built=True>\n",
      "<Activation name=25_layer, built=True>\n",
      "<Activation name=18_layer, built=True>\n",
      "<BatchNormalization name=26_layer, built=True>\n",
      "<BatchNormalization name=19_layer, built=True>\n",
      "<Dropout name=27_layer, built=True>\n",
      "<Dropout name=20_layer, built=True>\n",
      "<Dense name=28_layer, built=True>\n",
      "<Dense name=21_layer, built=True>\n",
      "<Activation name=cifar10, built=True>\n",
      "<Activation name=angle, built=True>\n"
     ]
    }
   ],
   "source": [
    "obj=custom_MTL()\n",
    "obj.load_weights()\n",
    "\n",
    "# out=obj.model.predict(image)\n",
    "obj.print_lays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x70ce882ec7c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "Elapsed Time: 0.09987428796011955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.0797014 , 0.07793119, 0.07088789, 0.11130471, 0.10851418,\n",
       "         0.10154222, 0.16401647, 0.08009152, 0.09813018, 0.10788022]],\n",
       "       dtype=float32),\n",
       " array([[0.24713223, 0.20949385, 0.2326632 , 0.31071073]], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.execute_predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: <Conv2D name=1_conv2D_1, built=True>\n",
      "Executing: <Activation name=2_activation_1, built=True>\n",
      "Executing: <BatchNormalization name=3_batch_norm_1, built=True>\n",
      "Executing: <MaxPooling2D name=4_maxPool_1, built=True>\n",
      "Executing: <Dropout name=5_dropout_1, built=True>\n",
      "Executing: <Conv2D name=6_conv2D_2, built=True>\n",
      "Executing: <Activation name=7_activation_2, built=True>\n",
      "Executing: <BatchNormalization name=8_batch_norm_2, built=True>\n",
      "Executing: <MaxPooling2D name=9_maxPool_2, built=True>\n",
      "Executing: <Dropout name=10_dropout_2, built=True>\n",
      "Executing: <Conv2D name=11_conv2D_3, built=True>\n",
      "Executing: <Activation name=12_activation_3, built=True>\n",
      "Executing: <BatchNormalization name=13_batch_norm_3, built=True>\n",
      "Executing: <MaxPooling2D name=14_maxPool_3, built=True>\n",
      "Executing: <Dropout name=15_dropout_3, built=True>\n",
      "Executing: <Flatten name=23_layer, built=True>\n",
      "Executing: <Flatten name=16_layer, built=True>\n",
      "Executing: <Dense name=24_layer, built=True>\n",
      "Executing: <Dense name=17_layer, built=True>\n",
      "Executing: <Activation name=25_layer, built=True>\n",
      "Executing: <Activation name=18_layer, built=True>\n",
      "Executing: <BatchNormalization name=26_layer, built=True>\n",
      "Executing: <BatchNormalization name=19_layer, built=True>\n",
      "Executing: <Dropout name=27_layer, built=True>\n",
      "Executing: <Dropout name=20_layer, built=True>\n",
      "Executing: <Dense name=28_layer, built=True>\n",
      "Executing: <Dense name=21_layer, built=True>\n",
      "Executing: <Activation name=cifar10, built=True>\n",
      "Executing: <Activation name=angle, built=True>\n",
      "Elapsed Time: 0.01700947602512315\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'np_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m obj\u001b[38;5;241m.\u001b[39mexecute_lbl(image)\n",
      "Cell \u001b[0;32mIn[29], line 87\u001b[0m, in \u001b[0;36mcustom_MTL.execute_lbl\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     85\u001b[0m el2\u001b[38;5;241m=\u001b[39met2\u001b[38;5;241m-\u001b[39mst2\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElapsed Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mel2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnp_array,buffer\n",
      "File \u001b[0;32m~/anaconda3/envs/nnsc/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:260\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    254\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    255\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    256\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'np_array'"
     ]
    }
   ],
   "source": [
    "obj.execute_lbl(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
