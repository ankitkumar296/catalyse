{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 19:19:40.642541: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-30 19:19:40.645305: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-30 19:19:40.675983: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 19:19:41.176106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as ker\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras import Input as innp\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class squeeznet():\n",
    "    def __init__(self,input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0) -> None:\n",
    "        \n",
    "        self.map=[[-1,[0],[0]],[0,[0],[0]],[0,[0],[0]],\n",
    "                  [1,[0],[0,1]],[1,[0],[0,2]],[0,[1],[0]],\n",
    "                  [3,[0,2],[0,3]],[1,[0],[0,1]],[1,[0],[0,2]],\n",
    "                  [0,[1],[0]],[2,[0,2],[0]],[2,[0,3],[0]],\n",
    "                  [1,[0],[0,1]],[1,[0],[0,2]],[0,[1],[0]],\n",
    "                  [2,[0,2],[0]],[1,[0],[0,3]],[1,[0],[0,1]],\n",
    "                  [1,[0],[0,2]],[0,[1],[0]],[2,[0,2],[0]],\n",
    "                  [2,[0,3],[0]],[1,[0],[0,1]],[1,[0],[0,2]],\n",
    "                  [0,[1],[0]],[3,[0,2],[0,3]],[1,[0],[0,1]],\n",
    "                  [1,[0],[0,2]],[0,[1],[0]],[2,[0,2],[0]],\n",
    "                  [2,[0,3],[0]],[1,[0],[0,1]],[1,[0],[0,2]],\n",
    "                  [0,[1],[0]],[2,[0,2],[0]],[1,[0],[0,3]],\n",
    "                  [1,[0],[0,1]],[1,[0],[0,2]],[0,[1],[0]],\n",
    "                  [2,[0,2],[0]],[2,[0,3],[0]],[0,[0],[0]],\n",
    "                  [0,[0],[0]],[0,[0],[0]],[0,[0],[0]],[0,[0],[0]]]\n",
    "        self.layer_list=[]\n",
    "        input_img = Input(shape=input_shape)\n",
    "        self.model=ker.Sequential\n",
    "        x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "        \n",
    "        x = self.create_fire_module(x, int(16*compression), name='fire2')\n",
    "        x = self.create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "        x = self.create_fire_module(x, int(32*compression), name='fire4')\n",
    "        \n",
    "        x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "        \n",
    "        x = self.create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "        x = self.create_fire_module(x, int(48*compression), name='fire6')\n",
    "        x = self.create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "        x = self.create_fire_module(x, int(64*compression), name='fire8')\n",
    "        \n",
    "        x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "        \n",
    "        x = self.create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "        if dropout_rate:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "            \n",
    "        x = self.output(x, nb_classes)\n",
    "        \n",
    "        self.model=Model(inputs=(input_img), outputs=x)\n",
    "\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def output(self,x, nb_classes):\n",
    "        x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "        x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "        x = Activation(\"softmax\", name='softmax')(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def create_fire_module(self,x, nb_squeeze_filter, name, use_bypass=False):\n",
    "            \n",
    "        nb_expand_filter = 4 * nb_squeeze_filter\n",
    "        squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "        expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "        expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "        \n",
    "        axis = self.get_axis()\n",
    "        x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "        \n",
    "        if use_bypass:\n",
    "            x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "            \n",
    "        return x_ret\n",
    "\n",
    "\n",
    "    def get_axis(self):\n",
    "        axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "        return axis\n",
    "    \n",
    "    def print_summary(self):\n",
    "        print(self.model.summary())\n",
    "    def load_weights(self):\n",
    "        self.model.load_weights('./squeeznet_model.h5')\n",
    "        pass\n",
    "    \n",
    "    def execute_predict(self, input_data):\n",
    "        st1=time.perf_counter()\n",
    "        out=self.model.predict(input_data)\n",
    "        et1=time.perf_counter()\n",
    "        el=et1-st1\n",
    "        print(el)\n",
    "        return out\n",
    "    def print_layrs(self):\n",
    "        i=0\n",
    "        for lay in self.model.layers:\n",
    "            self.layer_list.append(lay)\n",
    "            print(f'Index: {i} --> {lay.name}')\n",
    "            i+=1\n",
    "    def execute_lbl(self, input_data):\n",
    "        st2=time.perf_counter()\n",
    "        self.buffer=[None,None,None,None]\n",
    "        self.buffer[0]=input_data\n",
    "        \n",
    "        for idx in range(len(self.model.layers)):\n",
    "            \n",
    "            curr_lay=self.model.layers[idx]\n",
    "            \n",
    "            match self.map[idx][0]:\n",
    "                \n",
    "                case -1:\n",
    "                    self.buffer[self.map[idx][2][0]]=input_data\n",
    "                case 0:\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 1:\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 2:\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                case 3:\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                    \n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(el2)\n",
    "        return self.buffer[0].numpy()\n",
    "    \n",
    "    def get_input_list(self, input_data):\n",
    "        st2=time.perf_counter()\n",
    "        self.buffer=[None,None,None,None]\n",
    "        self.buffer[0]=input_data\n",
    "        self.input_list=[0]*44\n",
    "        print(f'Number_of_layers : {len(self.model.layers)}')\n",
    "        for idx in range(len(self.model.layers)):\n",
    "            \n",
    "            curr_lay=self.model.layers[idx]\n",
    "            \n",
    "            match self.map[idx][0]:\n",
    "                \n",
    "                case -1:\n",
    "                    self.input_list[idx]=input_data\n",
    "                    self.buffer[self.map[idx][2][0]]=input_data\n",
    "                case 0:\n",
    "                    self.input_list[idx]=self.buffer[self.map[idx][1][0]]\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 1:\n",
    "                    self.input_list[idx]=self.buffer[self.map[idx][1][0]]\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 2:\n",
    "                    self.input_list[idx]=[self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]]\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                case 3:\n",
    "                    self.input_list[idx]=[self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]]\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                    \n",
    "        print(f\"Input List Lenght : {len(self.input_list)}\")\n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(el2)\n",
    "        return self.input_list\n",
    "    \n",
    "    def execute_on_core(self,layer_id,input_data):\n",
    "        # dummy_data=dummy_data\n",
    "        # print(self.layer_list[layer_id].name)\n",
    "        self.temp_out=self.layer_list[layer_id](input_data)\n",
    "        \n",
    "        return self.temp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_execution_time(target_instance, target_method, core_id=0, *args):\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id])\n",
    "    except AttributeError:\n",
    "        pass  \n",
    "    start_time = time.perf_counter()\n",
    "    tt=getattr(target_instance, target_method)(*args)\n",
    "    end_time = time.perf_counter()\n",
    "    execution_time = end_time - start_time\n",
    "    # print(f\"Execution time on core {core_id}: {execution_time} seconds\")\n",
    "    return execution_time\n",
    "\n",
    "def compute_pair_execution_time(target_instance, target_method, core_id=[0,0], *args):\n",
    "    \n",
    "    st1=time.perf_counter()\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id[0]])\n",
    "    except AttributeError:\n",
    "        pass  \n",
    "    et1=time.perf_counter()\n",
    "    layer=args[0]\n",
    "    inp_seq=args[1]\n",
    "    st2 = time.perf_counter()\n",
    "    tt=getattr(target_instance, target_method)(layer[0],inp_seq[0],'dum')\n",
    "    et2 = time.perf_counter()\n",
    "    \n",
    "    st3=time.perf_counter()\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id[1]])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    et3=time.perf_counter()\n",
    "    st4=time.perf_counter()\n",
    "    tt2=getattr(target_instance, target_method)(layer[1],inp_seq[1],tt)\n",
    "    et4 = time.perf_counter()\n",
    "    \n",
    "    el1=et4-st1\n",
    "    el2=et2-st2\n",
    "    el3=et3-st3\n",
    "    el4=et4-st4\n",
    "    execution_time = el1+el2+el3+el4\n",
    "    # print(f\"Execution time on core {core_id}: {execution_time} seconds\")\n",
    "    return el1,tt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_LAYERS=44\n",
    "NO_OF_CPU=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_grid(obj,layer_ids,core_ids,input_data):\n",
    "    # temp=[0]*2\n",
    "    temp_out=input_data\n",
    "    # st=time.perf_counter()\n",
    "    # for lay in range(len(layer_ids)):\n",
    "    temp,temp_out=compute_pair_execution_time(obj,'execute_on_core',core_ids,layer_ids,temp_out)  \n",
    "        \n",
    "    # et=time.perf_counter()\n",
    "    # el=et-st\n",
    "    return temp, temp\n",
    "    \n",
    "\n",
    "def perform_grid(obj,lays,inp_seq):\n",
    "    res=np.zeros((NO_OF_CPU,NO_OF_CPU),dtype =  float)\n",
    "    for i in range(NO_OF_CPU):\n",
    "        for j in range(NO_OF_CPU):\n",
    "            #Now schedule this function on the CPU-0 to run the two layers on the different CPUs\n",
    "            # temp,res[i][j]= compute_execution_time_of_function(try_grid,0,obj,lays,[i,j],inp_seq)\n",
    "            # st=time.perf_counter()\n",
    "            res[i][j],temp=try_grid(obj,lays,[i,j],inp_seq)\n",
    "            \n",
    "            # et=time.perf_counter()\n",
    "            # el=et-st\n",
    "            # res[i][j]=el\n",
    "        time.sleep(0.5)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(num_list):\n",
    "\n",
    "    if not num_list:\n",
    "        return None  # Return None if the list is empty\n",
    "\n",
    "    total = sum(num_list)  # Calculate the sum of all numbers in the list\n",
    "    mean = total / len(num_list)  # Calculate the mean by dividing the sum by the number of elements\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_2d_list_to_csv(data, file_name):\n",
    "    \"\"\"\n",
    "    Save a 2D list to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        data (list): The 2D list to be saved.\n",
    "        file_name (str): The name of the CSV file to be created.\n",
    "    \"\"\"\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "    print(f'CSV file \"{file_name}\" has been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 --> input_layer_1\n",
      "Index: 1 --> conv1\n",
      "Index: 2 --> maxpool1\n",
      "Index: 3 --> fire2_squeeze\n",
      "Index: 4 --> fire2_expand_1x1\n",
      "Index: 5 --> fire2_expand_3x3\n",
      "Index: 6 --> fire2_concatenate\n",
      "Index: 7 --> fire3_squeeze\n",
      "Index: 8 --> fire3_expand_1x1\n",
      "Index: 9 --> fire3_expand_3x3\n",
      "Index: 10 --> fire3_concatenate\n",
      "Index: 11 --> fire3_concatenate_bypass\n",
      "Index: 12 --> fire4_squeeze\n",
      "Index: 13 --> fire4_expand_1x1\n",
      "Index: 14 --> fire4_expand_3x3\n",
      "Index: 15 --> fire4_concatenate\n",
      "Index: 16 --> maxpool4\n",
      "Index: 17 --> fire5_squeeze\n",
      "Index: 18 --> fire5_expand_1x1\n",
      "Index: 19 --> fire5_expand_3x3\n",
      "Index: 20 --> fire5_concatenate\n",
      "Index: 21 --> fire5_concatenate_bypass\n",
      "Index: 22 --> fire6_squeeze\n",
      "Index: 23 --> fire6_expand_1x1\n",
      "Index: 24 --> fire6_expand_3x3\n",
      "Index: 25 --> fire6_concatenate\n",
      "Index: 26 --> fire7_squeeze\n",
      "Index: 27 --> fire7_expand_1x1\n",
      "Index: 28 --> fire7_expand_3x3\n",
      "Index: 29 --> fire7_concatenate\n",
      "Index: 30 --> fire7_concatenate_bypass\n",
      "Index: 31 --> fire8_squeeze\n",
      "Index: 32 --> fire8_expand_1x1\n",
      "Index: 33 --> fire8_expand_3x3\n",
      "Index: 34 --> fire8_concatenate\n",
      "Index: 35 --> maxpool8\n",
      "Index: 36 --> fire9_squeeze\n",
      "Index: 37 --> fire9_expand_1x1\n",
      "Index: 38 --> fire9_expand_3x3\n",
      "Index: 39 --> fire9_concatenate\n",
      "Index: 40 --> fire9_concatenate_bypass\n",
      "Index: 41 --> conv10\n",
      "Index: 42 --> avgpool10\n",
      "Index: 43 --> softmax\n",
      "Number_of_layers : 44\n",
      "Input List Lenght : 44\n",
      "0.027692272968124598\n"
     ]
    }
   ],
   "source": [
    "obj=squeeznet(input_shape=(224,224,3),nb_classes=1000,use_bypass=True)\n",
    "obj.load_weights()\n",
    "obj.print_layrs()\n",
    "images = np.random.rand(1,224,224,3)\n",
    "INPUT_LIST=obj.get_input_list(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file \"single_layer_profile_squeeznet_for_percentage.csv\" has been created.\n",
      "CSV file \"single_layer_ave_profile_squeeznet_for_percentage.csv\" has been created.\n"
     ]
    }
   ],
   "source": [
    "EXP=25\n",
    "dummy=[0]*NO_OF_CPU\n",
    "layers_ex=[dummy]\n",
    "layers_ex_ave=[dummy]\n",
    "for l in range(1,NO_OF_LAYERS):\n",
    "    cpu_ex=[]\n",
    "    cpu_ex_avg=[]\n",
    "    for cpu in range(NO_OF_CPU):\n",
    "        temp=[]\n",
    "        for i in range(EXP):\n",
    "            temp.append(compute_execution_time(obj,'execute_on_core',cpu,l,INPUT_LIST[l]))\n",
    "        \n",
    "        temp1=calculate_mean(temp)\n",
    "        temp2=min(temp)\n",
    "        cpu_ex.append(temp2)\n",
    "        cpu_ex_avg.append(temp1)\n",
    "    time.sleep(0.5)\n",
    "    layers_ex.append(cpu_ex)\n",
    "    layers_ex_ave.append(cpu_ex_avg)\n",
    "\n",
    "\n",
    "save_2d_list_to_csv(layers_ex, \"./readings/single_layer_profile_squeeznet_for_percentage.csv\")\n",
    "save_2d_list_to_csv(layers_ex_ave, \"./readings/single_layer_ave_profile_squeeznet_for_percentage.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
