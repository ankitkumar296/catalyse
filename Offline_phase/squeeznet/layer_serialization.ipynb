{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 12:32:58.740441: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 12:32:58.742954: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 12:32:58.771743: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 12:32:59.265626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as ker\n",
    "from tensorflow.keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from tensorflow.keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras import Input as innp\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class squeeznet():\n",
    "    def __init__(self,input_shape, nb_classes, use_bypass=False, dropout_rate=None, compression=1.0) -> None:\n",
    "        \n",
    "        self.map=[[-1,[0],[0]],[0,[0],[0]],[0,[0],[0]],\n",
    "                  [1,[0],[0,1]],[1,[0],[0,2]],[0,[1],[0]],\n",
    "                  [3,[0,2],[0,3]],[1,[0],[0,1]],[1,[0],[0,2]],\n",
    "                  [0,[1],[0]],[2,[0,2],[0]],[2,[0,3],[0]],\n",
    "                  [1,[0],[0,1]],[1,[0],[0,2]],[0,[1],[0]],\n",
    "                  [2,[0,2],[0]],[1,[0],[0,3]],[1,[0],[0,1]],\n",
    "                  [1,[0],[0,2]],[0,[1],[0]],[2,[0,2],[0]],\n",
    "                  [2,[0,3],[0]],[1,[0],[0,1]],[1,[0],[0,2]],\n",
    "                  [0,[1],[0]],[3,[0,2],[0,3]],[1,[0],[0,1]],\n",
    "                  [1,[0],[0,2]],[0,[1],[0]],[2,[0,2],[0]],\n",
    "                  [2,[0,3],[0]],[1,[0],[0,1]],[1,[0],[0,2]],\n",
    "                  [0,[1],[0]],[2,[0,2],[0]],[1,[0],[0,3]],\n",
    "                  [1,[0],[0,1]],[1,[0],[0,2]],[0,[1],[0]],\n",
    "                  [2,[0,2],[0]],[2,[0,3],[0]],[0,[0],[0]],\n",
    "                  [0,[0],[0]],[0,[0],[0]],[0,[0],[0]],[0,[0],[0]]]\n",
    "        self.layer_list=[]\n",
    "        self.weight_set=False\n",
    "        self.partition_done = False\n",
    "        input_img = Input(shape=input_shape)\n",
    "        self.model=ker.Sequential\n",
    "        x = Conv2D(int(96*compression), (7,7), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "        x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "        \n",
    "        x = self.create_fire_module(x, int(16*compression), name='fire2')\n",
    "        x = self.create_fire_module(x, int(16*compression), name='fire3', use_bypass=use_bypass)\n",
    "        x = self.create_fire_module(x, int(32*compression), name='fire4')\n",
    "        \n",
    "        x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool4')(x)\n",
    "        \n",
    "        x = self.create_fire_module(x, int(32*compression), name='fire5', use_bypass=use_bypass)\n",
    "        x = self.create_fire_module(x, int(48*compression), name='fire6')\n",
    "        x = self.create_fire_module(x, int(48*compression), name='fire7', use_bypass=use_bypass)\n",
    "        x = self.create_fire_module(x, int(64*compression), name='fire8')\n",
    "        \n",
    "        x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool8')(x)\n",
    "        \n",
    "        x = self.create_fire_module(x, int(64*compression), name='fire9', use_bypass=use_bypass)\n",
    "\n",
    "        if dropout_rate:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "            \n",
    "        x = self.output(x, nb_classes)\n",
    "        \n",
    "        self.model=Model(inputs=(input_img), outputs=x)\n",
    "\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def output(self,x, nb_classes):\n",
    "        x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "        x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "        x = Activation(\"softmax\", name='softmax')(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def create_fire_module(self,x, nb_squeeze_filter, name, use_bypass=False):\n",
    "            \n",
    "        nb_expand_filter = 4 * nb_squeeze_filter\n",
    "        squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "        expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "        expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "        \n",
    "        axis = self.get_axis()\n",
    "        x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "        \n",
    "        if use_bypass:\n",
    "            x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "            \n",
    "        return x_ret\n",
    "\n",
    "\n",
    "    def get_axis(self):\n",
    "        axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "        return axis\n",
    "    \n",
    "    def print_summary(self):\n",
    "        print(self.model.summary())\n",
    "    def load_weights(self):\n",
    "        self.model.load_weights('./squeeznet_model.h5')\n",
    "        self.weight_set=True\n",
    "        return\n",
    "    \n",
    "    def load_input(self):\n",
    "        self.input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "        self.input_loaded=True\n",
    "        return self.input_data\n",
    "    def make_partition(self):\n",
    "        self.layer_list=[]\n",
    "        self.NO_OF_LAYERS= len(self.model.layers)\n",
    "        \n",
    "        for i in range(self.NO_OF_LAYERS):\n",
    "            self.temp_layer=self.model.layers[i]\n",
    "            self.layer_list.append(self.temp_layer)\n",
    "            \n",
    "        self.partition_done = True\n",
    "        print('\\_______Partitioning Done')\n",
    "    \n",
    "    \n",
    "    def save_pickeled_layers(self):\n",
    "        if not self.weight_set:\n",
    "            self.loadWeights()\n",
    "\n",
    "        \n",
    "        if not self.partition_done:\n",
    "            self.make_partition()\n",
    "        save_dir='./../pickled_layers'\n",
    "        for i in range(len(self.layer_list)):\n",
    "            fname=f'./{save_dir}/custum_mtl_layer_{i}.pkl'\n",
    "            layer_weights_and_config = {\n",
    "                'weights': self.layer_list[i].get_weights(),\n",
    "                'config': tf.keras.layers.serialize(self.layer_list[i])}\n",
    "            with open(fname, 'wb') as f:\n",
    "                pickle.dump(layer_weights_and_config, f)\n",
    "              \n",
    "        return\n",
    "    \n",
    "    def load_layer(self, layer_id):\n",
    "        self.dir_path='pickled_layers'\n",
    "        fname=f'./{self.dir_path}/squeeznet_layer_{layer_id}.pkl'\n",
    "        with open(fname, 'rb') as f:\n",
    "            layer_config = pickle.load(f)\n",
    "            \n",
    "        self.layer = tf.keras.layers.deserialize(config= layer_config['config'])\n",
    "            \n",
    "        # self.layer_list.append(layer)\n",
    "        self.layer.set_weights(layer_config['weights'])\n",
    "        return self.layer\n",
    "      \n",
    "    def execute_predict(self, input_data):\n",
    "        st1=time.perf_counter()\n",
    "        out=self.model.predict(input_data)\n",
    "        et1=time.perf_counter()\n",
    "        el=et1-st1\n",
    "        print(el)\n",
    "        return out\n",
    "    def print_layrs(self):\n",
    "        i=0\n",
    "        for lay in self.model.layers:\n",
    "            self.layer_list.append(lay)\n",
    "            print(f'Index: {i} --> {lay.name}')\n",
    "            i+=1\n",
    "    def execute_lbl(self, input_data):\n",
    "        st2=time.perf_counter()\n",
    "        self.buffer=[None,None,None,None]\n",
    "        self.buffer[0]=input_data\n",
    "        \n",
    "        for idx in range(len(self.model.layers)):\n",
    "            \n",
    "            curr_lay=self.model.layers[idx]\n",
    "            print(f\"Executing Layer -> {idx}\")\n",
    "            match self.map[idx][0]:\n",
    "                \n",
    "                case -1:\n",
    "                    self.buffer[self.map[idx][2][0]]=input_data\n",
    "                case 0:\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 1:\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 2:\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                case 3:\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                    \n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(el2)\n",
    "        return self.buffer[0].numpy()\n",
    "    \n",
    "    def execute_lbl_serial(self, input_data):\n",
    "        st2=time.perf_counter()\n",
    "        self.buffer=[None,None,None,None]\n",
    "        self.buffer[0]=input_data\n",
    "        \n",
    "        for idx in range(len(self.model.layers)):\n",
    "            \n",
    "            curr_lay=self.load_layer(idx)\n",
    "            print(f\"Executing Layer -> {idx}\")\n",
    "            match self.map[idx][0]:\n",
    "                \n",
    "                case -1:\n",
    "                    self.buffer[self.map[idx][2][0]]=input_data\n",
    "                case 0:\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 1:\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 2:\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                case 3:\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                    \n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(el2)\n",
    "        return self.buffer[0].numpy()\n",
    "    \n",
    "    def get_input_list(self, input_data):\n",
    "        st2=time.perf_counter()\n",
    "        self.buffer=[None,None,None,None]\n",
    "        self.buffer[0]=input_data\n",
    "        self.input_list=[0]*44\n",
    "        print(f'Number_of_layers : {len(self.model.layers)}')\n",
    "        for idx in range(len(self.model.layers)):\n",
    "            \n",
    "            curr_lay=self.model.layers[idx]\n",
    "            \n",
    "            match self.map[idx][0]:\n",
    "                \n",
    "                case -1:\n",
    "                    self.input_list[idx]=input_data\n",
    "                    self.buffer[self.map[idx][2][0]]=input_data\n",
    "                case 0:\n",
    "                    self.input_list[idx]=self.buffer[self.map[idx][1][0]]\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 1:\n",
    "                    self.input_list[idx]=self.buffer[self.map[idx][1][0]]\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay(self.buffer[self.map[idx][1][0]])\n",
    "                case 2:\n",
    "                    self.input_list[idx]=[self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]]\n",
    "                    self.buffer[self.map[idx][2][0]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                case 3:\n",
    "                    self.input_list[idx]=[self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]]\n",
    "                    self.buffer[self.map[idx][2][0]]=self.buffer[self.map[idx][2][1]]=curr_lay([self.buffer[self.map[idx][1][0]],self.buffer[self.map[idx][1][1]]])\n",
    "                    \n",
    "        print(f\"Input List Lenght : {len(self.input_list)}\")\n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(el2)\n",
    "        return self.input_list\n",
    "    \n",
    "    def execute_on_core(self,layer_id,input_data,dummy_data):\n",
    "        dummy_data=dummy_data\n",
    "        # print(self.layer_list[layer_id].name)\n",
    "        self.temp_out=self.layer_list[layer_id](input_data)\n",
    "        \n",
    "        return self.temp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_LAYERS=44\n",
    "NO_OF_CPU=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=squeeznet(input_shape=(224,224,3),nb_classes=1000,use_bypass=True)\n",
    "obj.load_weights()\n",
    "images = np.random.rand(1,224,224,3)\n",
    "# INPUT_LIST=obj.get_input_list(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj.make_partition\n",
    "# obj.save_pickeled_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "0.176245309994556\n",
      "Executing Layer -> 0\n",
      "Executing Layer -> 1\n",
      "Executing Layer -> 2\n",
      "Executing Layer -> 3\n",
      "Executing Layer -> 4\n",
      "Executing Layer -> 5\n",
      "Executing Layer -> 6\n",
      "Executing Layer -> 7\n",
      "Executing Layer -> 8\n",
      "Executing Layer -> 9\n",
      "Executing Layer -> 10\n",
      "Executing Layer -> 11\n",
      "Executing Layer -> 12\n",
      "Executing Layer -> 13\n",
      "Executing Layer -> 14\n",
      "Executing Layer -> 15\n",
      "Executing Layer -> 16\n",
      "Executing Layer -> 17\n",
      "Executing Layer -> 18\n",
      "Executing Layer -> 19\n",
      "Executing Layer -> 20\n",
      "Executing Layer -> 21\n",
      "Executing Layer -> 22\n",
      "Executing Layer -> 23\n",
      "Executing Layer -> 24\n",
      "Executing Layer -> 25\n",
      "Executing Layer -> 26\n",
      "Executing Layer -> 27\n",
      "Executing Layer -> 28\n",
      "Executing Layer -> 29\n",
      "Executing Layer -> 30\n",
      "Executing Layer -> 31\n",
      "Executing Layer -> 32\n",
      "Executing Layer -> 33\n",
      "Executing Layer -> 34\n",
      "Executing Layer -> 35\n",
      "Executing Layer -> 36\n",
      "Executing Layer -> 37\n",
      "Executing Layer -> 38\n",
      "Executing Layer -> 39\n",
      "Executing Layer -> 40\n",
      "Executing Layer -> 41\n",
      "Executing Layer -> 42\n",
      "Executing Layer -> 43\n",
      "0.08279936900362372\n"
     ]
    }
   ],
   "source": [
    "out1=obj.execute_predict(images)\n",
    "out2=obj.execute_lbl(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000593718141"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(out1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999998835847"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(out2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpl=(1,(1,224,224,3),(1,224,224,3))\n",
    "len(tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : (1, 224, 224, 3)\n",
      "1 : (1, 224, 224, 3)\n",
      "2 : (1, 112, 112, 96)\n",
      "3 : (1, 55, 55, 96)\n",
      "4 : (1, 55, 55, 16)\n",
      "5 : (1, 55, 55, 16)\n",
      "6 : (1, (1, 55, 55, 64), (1, 55, 55, 64))\n",
      "7 : (1, 55, 55, 128)\n",
      "8 : (1, 55, 55, 16)\n",
      "9 : (1, 55, 55, 16)\n",
      "10 : (1, (1, 55, 55, 64), (1, 55, 55, 64))\n",
      "11 : (1, (1, 55, 55, 128), (1, 55, 55, 128))\n",
      "12 : (1, 55, 55, 128)\n",
      "13 : (1, 55, 55, 32)\n",
      "14 : (1, 55, 55, 32)\n",
      "15 : (1, (1, 55, 55, 128), (1, 55, 55, 128))\n",
      "16 : (1, 55, 55, 256)\n",
      "17 : (1, 27, 27, 256)\n",
      "18 : (1, 27, 27, 32)\n",
      "19 : (1, 27, 27, 32)\n",
      "20 : (1, (1, 27, 27, 128), (1, 27, 27, 128))\n",
      "21 : (1, (1, 27, 27, 256), (1, 27, 27, 256))\n",
      "22 : (1, 27, 27, 256)\n",
      "23 : (1, 27, 27, 48)\n",
      "24 : (1, 27, 27, 48)\n",
      "25 : (1, (1, 27, 27, 192), (1, 27, 27, 192))\n",
      "26 : (1, 27, 27, 384)\n",
      "27 : (1, 27, 27, 48)\n",
      "28 : (1, 27, 27, 48)\n",
      "29 : (1, (1, 27, 27, 192), (1, 27, 27, 192))\n",
      "30 : (1, (1, 27, 27, 384), (1, 27, 27, 384))\n",
      "31 : (1, 27, 27, 384)\n",
      "32 : (1, 27, 27, 64)\n",
      "33 : (1, 27, 27, 64)\n",
      "34 : (1, (1, 27, 27, 256), (1, 27, 27, 256))\n",
      "35 : (1, 27, 27, 512)\n",
      "36 : (1, 13, 13, 512)\n",
      "37 : (1, 13, 13, 64)\n",
      "38 : (1, 13, 13, 64)\n",
      "39 : (1, (1, 13, 13, 256), (1, 13, 13, 256))\n",
      "40 : (1, (1, 13, 13, 512), (1, 13, 13, 512))\n",
      "41 : (1, 13, 13, 512)\n",
      "42 : (1, 13, 13, 1000)\n",
      "43 : (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "inp_shaps=[(1,224,224,3),(1,224, 224, 3),(1,112, 112, 96),(1,55, 55, 96),\n",
    "           (1,55, 55, 16),(1,55, 55, 16),(1,(1, 55, 55, 64),(1, 55, 55, 64)),(1,55, 55, 128),\n",
    "           (1,55, 55, 16),(1,55, 55, 16),(1,(1, 55, 55, 64),(1, 55, 55, 64)),(1,(1, 55, 55, 128),(1, 55, 55, 128)),\n",
    "           (1,55, 55, 128),(1,55, 55, 32),(1,55, 55, 32),(1,(1, 55, 55, 128),(1, 55, 55, 128)),\n",
    "           (1,55, 55, 256),(1,27, 27, 256),(1,27, 27, 32),(1,27, 27, 32),\n",
    "           (1,(1, 27, 27, 128),(1, 27, 27, 128)),(1,(1, 27, 27, 256),(1, 27, 27, 256)),(1,27, 27, 256),(1,27, 27, 48),\n",
    "           (1,27, 27, 48),(1,(1, 27, 27, 192),(1, 27, 27, 192)),(1,27, 27, 384),(1,27, 27, 48),\n",
    "           (1,27, 27, 48),(1,(1, 27, 27, 192),(1, 27, 27, 192)),(1,(1, 27, 27, 384),(1, 27, 27, 384)),(1,27, 27, 384),\n",
    "           (1,27, 27, 64),(1,27, 27, 64),(1,(1, 27, 27, 256),(1, 27, 27, 256)),(1,27, 27, 512),\n",
    "           (1,13, 13, 512),(1,13, 13, 64),(1,13, 13, 64),(1,(1, 13, 13, 256),(1, 13, 13, 256)),\n",
    "           (1,(1, 13, 13, 512),(1, 13, 13, 512)),(1,13, 13, 512),(1,13, 13, 1000),(1,1000)]\n",
    "\n",
    "len(inp_shaps)\n",
    "for i,j in enumerate(inp_shaps):\n",
    "    print(f\"{i} : {j}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
