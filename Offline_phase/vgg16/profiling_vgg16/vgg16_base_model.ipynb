{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16_in():\n",
    "    def __init__(self):\n",
    "        self.weight_set=False\n",
    "        self.partition_done=False\n",
    "        self.input_loaded=False\n",
    "        self.layer_list=[]\n",
    "        \n",
    "        \n",
    "        self.model = Sequential()\n",
    "        \n",
    "        # Block 1\n",
    "        self.model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "        self.model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # Block 2\n",
    "        self.model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # Block 3\n",
    "        self.model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # Block 4\n",
    "        self.model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # Block 5\n",
    "        self.model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "        self.model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # Flatten\n",
    "        self.model.add(Flatten())\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.model.add(Dense(4096, activation='relu'))\n",
    "        self.model.add(Dense(4096, activation='relu'))\n",
    "        self.model.add(Dense(1000, activation='softmax'))  # Output layer with 1000 classes for ImageNet\n",
    "        # tf.keras.utils.plot_model(self.model, to_file='vgg16_model.png', show_shapes=True)\n",
    "        \n",
    "        \n",
    "    def model_info(self):\n",
    "        self.no_of_layers=len(self.model.layers)\n",
    "        print(\"\\_____Number of Layers in Model: \",self.no_of_layers)\n",
    "        print(\"\\_____Weights are loaded: \",self.weight_set)\n",
    "        print(\"\\_____Input loaded to Model: \",self.input_loaded)\n",
    "        print('\\_____Partitioning Done: ',self.partition_done)\n",
    "        \n",
    "        print(type(self.model.layers[0]))\n",
    "    def load_input(self):\n",
    "        self.input_data = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "        self.input_loaded=True\n",
    "    def loadWeights(self):\n",
    "        self.model.load_weights('./../vgg16_imagenet_5epoch.h5')\n",
    "        self.weight_set=True\n",
    "        print(\"\\_____Weights are loaded to the \")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_layer(self, layer_id):\n",
    "        return self.layer_list[layer_id]\n",
    "        \n",
    "    def make_partition(self):\n",
    "        self.NO_OF_LAYERS= len(self.model.layers)\n",
    "        \n",
    "        for i in range(self.NO_OF_LAYERS):\n",
    "            self.temp_layer=self.model.layers[i]\n",
    "            self.layer_list.append(self.temp_layer)\n",
    "            \n",
    "        self.partition_done = True\n",
    "        print('\\_______Partitioning Done')\n",
    "        \n",
    "    def execute_full_network(self):\n",
    "        if not self.input_loaded:\n",
    "            self.load_input()\n",
    "        print(\"I am in full Executioon\")\n",
    "        st1=time.perf_counter()\n",
    "        self.output=self.model.predict(self.input_data)\n",
    "        ed1=time.perf_counter()\n",
    "        \n",
    "        elt1=ed1-st1\n",
    "        elt1=float(elt1)\n",
    "        \n",
    "        return elt1,self.output\n",
    "        \n",
    "    def execute_full_network_sample(self,imp):\n",
    "        st1=time.perf_counter()        \n",
    "        self.output=self.model.predict(imp)\n",
    "        ed1=time.perf_counter()\n",
    "        \n",
    "        elt1=ed1-st1\n",
    "        elt1=float(elt1)        \n",
    "        return elt1\n",
    "    def execute_full_partition(self):\n",
    "        if not self.partition_done:\n",
    "            self.make_partition()\n",
    "        if not self.input_loaded:\n",
    "            self.load_input()\n",
    "            \n",
    "        self.temp_res=self.input_data\n",
    "        st2=time.perf_counter()\n",
    "        for i in range(self.NO_OF_LAYERS):\n",
    "            self.temp_res = self.layer_list[i](self.temp_res)\n",
    "        ed2=time.perf_counter()\n",
    "        self.temp_res=np.array(self.temp_res)\n",
    "        elt2=ed2-st2\n",
    "        elt2=float(elt2)\n",
    "        \n",
    "        return elt2,self.temp_res    \n",
    "    def execute_layer_by_layer_sample(self,inp):\n",
    "        temp_out=inp\n",
    "        for lay in self.layer_list:\n",
    "            \n",
    "            temp_out=lay(temp_out)\n",
    "               \n",
    "        temp_out=np.array(temp_out)\n",
    "                    \n",
    "        return temp_out\n",
    "    \n",
    "    def execute_on_core(self,layer_id,input_data):\n",
    "                \n",
    "        self.temp_out=self.layer_list[layer_id](input_data)\n",
    "        \n",
    "        return self.temp_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_execution_time(target_instance, target_method, core_id=0, *args):\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id])\n",
    "    except AttributeError:\n",
    "        pass  \n",
    "    start_time = time.perf_counter()\n",
    "    tt=getattr(target_instance, target_method)(*args)\n",
    "    end_time = time.perf_counter()\n",
    "    execution_time = end_time - start_time\n",
    "    # print(f\"Execution time on core {core_id}: {execution_time} seconds\")\n",
    "    return execution_time,tt\n",
    "\n",
    "def compute_pair_execution_time(target_instance, target_method, core_id=[0,0], *args):\n",
    "    \n",
    "    st1=time.perf_counter()\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id[0]])\n",
    "    except AttributeError:\n",
    "        pass  \n",
    "    et1=time.perf_counter()\n",
    "    next_layer=args[0]\n",
    "    st2 = time.perf_counter()\n",
    "    tt=getattr(target_instance, target_method)(*args)\n",
    "    et2 = time.perf_counter()\n",
    "    \n",
    "    st3=time.perf_counter()\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id[1]])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    et3=time.perf_counter()\n",
    "    st4=time.perf_counter()\n",
    "    tt2=getattr(target_instance, target_method)(next_layer+1,tt)\n",
    "    et4 = time.perf_counter()\n",
    "    \n",
    "    el1=et4-st1\n",
    "    el2=et2-st2\n",
    "    el3=et3-st3\n",
    "    el4=et4-st4\n",
    "    execution_time = el1+el2+el3+el4\n",
    "    # print(f\"Execution time on core {core_id}: {execution_time} seconds\")\n",
    "    return el1,tt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_CPU=24\n",
    "NO_OF_LAYER=22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def try_grid(obj,layer_ids,core_ids,input_data):\n",
    "    # temp=[0]*2\n",
    "    temp_out=input_data[0]\n",
    "    # st=time.perf_counter()\n",
    "    # for lay in range(len(layer_ids)):\n",
    "    temp,temp_out=compute_pair_execution_time(obj,'execute_on_core',core_ids,layer_ids[0],temp_out)  \n",
    "        \n",
    "    # et=time.perf_counter()\n",
    "    # el=et-st\n",
    "    return temp, temp\n",
    "    \n",
    "\n",
    "def perform_grid(obj,lays,inp_seq):\n",
    "    res=np.zeros((NO_OF_CPU,NO_OF_CPU),dtype =  float)\n",
    "    for i in range(NO_OF_CPU):\n",
    "        for j in range(NO_OF_CPU):\n",
    "            #Now schedule this function on the CPU-0 to run the two layers on the different CPUs\n",
    "            # temp,res[i][j]= compute_execution_time_of_function(try_grid,0,obj,lays,[i,j],inp_seq)\n",
    "            # st=time.perf_counter()\n",
    "            res[i][j],temp=try_grid(obj,lays,[i,j],inp_seq)\n",
    "            \n",
    "            # et=time.perf_counter()\n",
    "            # el=et-st\n",
    "            # res[i][j]=el\n",
    "        time.sleep(0.5)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_heatmap(readings,name):\n",
    "    plt.imshow(readings, cmap='cividis', interpolation='nearest')\n",
    "    path='./img/conn/'+name+'.png'\n",
    "    plt.colorbar()\n",
    "    plt.title(name)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def write_to_csv(name,res):\n",
    "    csv_file_path=name\n",
    "    row_headings =[str(i) for i in range(24)]\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(row_headings)\n",
    "        # Write each row of the array to the CSV file\n",
    "        for row in res:\n",
    "            \n",
    "            csv_writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\_____Weights are loaded to the \n",
      "\\_______Partitioning Done\n",
      "I am in full Executioon\n",
      "1/1 [==============================] - 0s 137ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20194394399004523,\n",
       " array([[8.51121172e-03, 9.32181440e-03, 7.95472786e-03, 9.61745623e-03,\n",
       "         6.65991940e-03, 8.63057841e-03, 8.00114777e-03, 5.25054475e-03,\n",
       "         1.22763403e-02, 6.62560854e-03, 1.26605649e-02, 1.00931125e-02,\n",
       "         7.79127423e-03, 7.76346913e-03, 7.66913360e-03, 7.79111544e-03,\n",
       "         1.03303064e-02, 6.66583097e-03, 8.42910539e-03, 1.23108355e-02,\n",
       "         6.18390134e-03, 7.89364334e-03, 6.94539910e-03, 8.93253647e-03,\n",
       "         5.82350278e-03, 8.77175387e-03, 6.29481347e-03, 6.33701915e-03,\n",
       "         7.88842235e-03, 3.07342084e-03, 9.93652642e-03, 9.93551314e-03,\n",
       "         4.17291839e-03, 4.17549908e-03, 6.95893727e-03, 8.69414303e-03,\n",
       "         6.92817383e-03, 1.00747291e-02, 8.34982470e-03, 8.13284703e-03,\n",
       "         9.63804964e-03, 8.26446153e-03, 7.93279428e-03, 5.49177965e-03,\n",
       "         9.67262685e-03, 9.66242049e-03, 8.36436730e-03, 7.04857241e-03,\n",
       "         5.91631094e-03, 9.29705519e-03, 1.21106440e-02, 7.75045250e-03,\n",
       "         1.01893041e-02, 8.78783688e-03, 8.02691933e-03, 6.84560183e-03,\n",
       "         1.05237477e-02, 1.04342923e-02, 8.31059460e-03, 1.27539411e-02,\n",
       "         7.23284017e-03, 1.09352581e-02, 7.12466193e-03, 8.37214570e-03,\n",
       "         9.14157741e-03, 9.17496905e-03, 7.53038749e-03, 6.43631816e-03,\n",
       "         2.78120092e-03, 9.03003477e-03, 7.76516832e-03, 9.38537437e-03,\n",
       "         5.86441811e-03, 7.47810258e-03, 4.83957306e-03, 6.77876966e-03,\n",
       "         7.80088967e-03, 6.87136920e-03, 8.73829983e-03, 8.52883700e-03,\n",
       "         8.03499855e-03, 1.02074575e-02, 9.02871229e-03, 1.18329851e-02,\n",
       "         9.33520868e-03, 1.09323580e-02, 7.09409965e-03, 1.26946578e-02,\n",
       "         1.05842873e-02, 5.08617749e-03, 6.68386370e-03, 1.18225850e-02,\n",
       "         1.00736292e-02, 8.12628120e-03, 9.39685665e-03, 1.18545117e-02,\n",
       "         6.93253474e-03, 7.73133710e-03, 6.22290140e-03, 1.28043117e-02,\n",
       "         6.12211227e-03, 8.86133313e-03, 9.81710199e-03, 6.62628468e-03,\n",
       "         1.13498922e-02, 8.10422562e-03, 1.14276372e-02, 7.57743791e-03,\n",
       "         8.14725924e-03, 8.98999814e-03, 7.72706559e-03, 4.92001278e-03,\n",
       "         9.02680028e-03, 7.74881011e-03, 7.29359128e-03, 6.32649520e-03,\n",
       "         9.54801682e-03, 5.78925572e-03, 8.47156718e-03, 8.17285571e-03,\n",
       "         3.09021357e-06, 2.91176252e-06, 3.64364155e-06, 2.52392238e-06,\n",
       "         3.08430162e-06, 3.15058560e-06, 3.89506113e-06, 3.28467831e-06,\n",
       "         3.14562590e-06, 2.04874732e-06, 1.99654914e-06, 3.79886410e-06,\n",
       "         2.86071258e-06, 3.37138613e-06, 1.86511204e-06, 2.72629245e-06,\n",
       "         3.44847376e-06, 2.93342464e-06, 2.51405618e-06, 2.22376252e-06,\n",
       "         2.95393465e-06, 3.73564762e-06, 3.82242752e-06, 2.76397486e-06,\n",
       "         3.52782195e-06, 2.70582700e-06, 2.94409961e-06, 2.28867930e-06,\n",
       "         3.76211460e-06, 2.06188406e-06, 3.12363886e-06, 3.45777039e-06,\n",
       "         2.85682745e-06, 3.35512755e-06, 2.77232743e-06, 3.09931261e-06,\n",
       "         3.62557898e-06, 3.33312232e-06, 2.49231357e-06, 3.27759381e-06,\n",
       "         2.29379702e-06, 3.30743592e-06, 3.54536019e-06, 3.32888771e-06,\n",
       "         2.69308885e-06, 3.09080610e-06, 3.24121629e-06, 2.55840746e-06,\n",
       "         3.64850234e-06, 3.08456629e-06, 3.04637774e-06, 1.95867187e-06,\n",
       "         2.98309078e-06, 2.73358978e-06, 2.69537304e-06, 2.44538774e-06,\n",
       "         2.89431773e-06, 2.50572384e-06, 2.93832136e-06, 2.43089039e-06,\n",
       "         2.64996879e-06, 2.34100867e-06, 1.99424471e-06, 3.16483556e-06,\n",
       "         3.20060599e-06, 3.33639787e-06, 4.36440860e-06, 2.82592578e-06,\n",
       "         3.12008115e-06, 2.72603233e-06, 2.47460980e-06, 3.22645633e-06,\n",
       "         4.24066820e-06, 2.91155425e-06, 4.02790874e-06, 2.36908704e-06,\n",
       "         2.34358845e-06, 4.03202876e-06, 2.53943722e-06, 3.26196800e-06,\n",
       "         2.73995033e-06, 4.38941561e-06, 4.10683106e-06, 3.29098657e-06,\n",
       "         3.27671546e-06, 3.08130871e-06, 2.36210235e-06, 2.78622406e-06,\n",
       "         3.00146553e-06, 2.34689196e-06, 3.01370142e-06, 4.02600381e-06,\n",
       "         2.55157511e-06, 4.37028348e-06, 2.77626441e-06, 3.48979893e-06,\n",
       "         2.10903568e-06, 2.32298771e-06, 2.58030832e-06, 2.81027906e-06,\n",
       "         3.50346750e-06, 6.07324864e-06, 2.32037519e-06, 3.81791688e-06,\n",
       "         4.24496966e-06, 3.12749899e-06, 2.47755906e-06, 3.48463391e-06,\n",
       "         4.07393873e-06, 2.40359645e-06, 2.86997602e-06, 4.11818519e-06,\n",
       "         4.37665631e-06, 3.86381680e-06, 3.06396441e-06, 3.81892960e-06,\n",
       "         2.91667061e-06, 3.57175986e-06, 3.51976337e-06, 2.26629732e-06,\n",
       "         1.48686092e-06, 3.53606424e-06, 2.97179531e-06, 3.32892250e-06,\n",
       "         3.95019015e-06, 2.87949752e-06, 4.48896117e-06, 2.36374080e-06,\n",
       "         2.59396211e-06, 3.71564397e-06, 2.90526896e-06, 2.73782962e-06,\n",
       "         3.55740735e-06, 4.99594898e-06, 3.21265497e-06, 2.60256047e-06,\n",
       "         2.76923060e-06, 5.28910459e-06, 3.24089797e-06, 4.19852813e-06,\n",
       "         3.03319302e-06, 4.13057523e-06, 2.95696168e-06, 3.56855594e-06,\n",
       "         2.98970690e-06, 2.56857015e-06, 3.68516066e-06, 4.08953656e-06,\n",
       "         3.89006800e-06, 2.62217236e-06, 3.38147129e-06, 3.08859899e-06,\n",
       "         3.37591314e-06, 4.03408239e-06, 3.31588740e-06, 3.98430529e-06,\n",
       "         3.35048503e-06, 3.70791986e-06, 3.13698001e-06, 3.79396170e-06,\n",
       "         2.34820163e-06, 2.73630508e-06, 2.38193206e-06, 3.89611614e-06,\n",
       "         2.46985178e-06, 3.74751221e-06, 3.01465298e-06, 2.98887721e-06,\n",
       "         3.04169203e-06, 3.19013247e-06, 2.60081129e-06, 2.34116919e-06,\n",
       "         3.77041556e-06, 3.39937424e-06, 2.93666312e-06, 2.22356744e-06,\n",
       "         2.90506409e-06, 3.41628038e-06, 3.24541679e-06, 3.12296265e-06,\n",
       "         3.94112885e-06, 4.14122860e-06, 2.57014085e-06, 3.31223691e-06,\n",
       "         3.29005798e-06, 2.62296021e-06, 3.21794437e-06, 2.76398259e-06,\n",
       "         2.30918499e-06, 2.66594066e-06, 2.80433278e-06, 3.72633940e-06,\n",
       "         2.85241458e-06, 4.70634313e-06, 1.99202259e-06, 2.88403771e-06,\n",
       "         4.15692148e-06, 4.01467787e-06, 2.18237619e-06, 2.57830357e-06,\n",
       "         4.16620060e-06, 2.56496446e-06, 2.37279528e-06, 2.90021967e-06,\n",
       "         1.82259657e-06, 3.56950568e-06, 3.15444004e-06, 3.78274035e-06,\n",
       "         2.37241966e-06, 3.77991637e-06, 4.39100859e-06, 3.07131336e-06,\n",
       "         3.87139289e-06, 3.49598122e-06, 2.22289941e-06, 2.98554414e-06,\n",
       "         4.01390434e-06, 2.42828605e-06, 3.69968279e-06, 3.78621235e-06,\n",
       "         2.85478495e-06, 2.95980021e-06, 3.10444216e-06, 3.01092928e-06,\n",
       "         3.33381490e-06, 3.06069342e-06, 3.46263414e-06, 3.83470979e-06,\n",
       "         2.47962498e-06, 3.46046204e-06, 3.61202615e-06, 3.67207167e-06,\n",
       "         2.86223531e-06, 2.61685864e-06, 2.71352519e-06, 4.96887696e-06,\n",
       "         3.00676584e-06, 2.99031990e-06, 2.76097148e-06, 3.61481739e-06,\n",
       "         3.80419328e-06, 3.51897802e-06, 2.74407444e-06, 2.32486718e-06,\n",
       "         2.92017467e-06, 3.40529914e-06, 1.84222631e-06, 2.72839407e-06,\n",
       "         2.17364800e-06, 2.87637158e-06, 2.11005977e-06, 2.38790017e-06,\n",
       "         3.32370746e-06, 4.10124949e-06, 2.84354655e-06, 4.05515857e-06,\n",
       "         3.06651623e-06, 3.35555933e-06, 2.70216515e-06, 3.54368035e-06,\n",
       "         3.11352392e-06, 3.05861590e-06, 3.70750627e-06, 2.57865759e-06,\n",
       "         2.37773338e-06, 3.47202217e-06, 3.33368803e-06, 5.45025023e-06,\n",
       "         2.64740243e-06, 3.05572075e-06, 4.06546269e-06, 3.53106998e-06,\n",
       "         3.23149106e-06, 3.98801194e-06, 2.31287027e-06, 3.68120209e-06,\n",
       "         2.75452794e-06, 2.87073158e-06, 3.17470858e-06, 3.10702194e-06,\n",
       "         2.76264132e-06, 2.69442717e-06, 2.56364387e-06, 3.01714954e-06,\n",
       "         2.83411168e-06, 2.61531432e-06, 4.56766747e-06, 3.16535807e-06,\n",
       "         2.50711764e-06, 2.74806280e-06, 3.66300560e-06, 2.71904787e-06,\n",
       "         3.52421716e-06, 3.54008307e-06, 4.36166010e-06, 2.43090199e-06,\n",
       "         4.51705137e-06, 2.02351384e-06, 3.95723328e-06, 2.41102339e-06,\n",
       "         3.64417292e-06, 2.25967824e-06, 2.83979330e-06, 4.15560180e-06,\n",
       "         2.82275028e-06, 4.50014250e-06, 2.64669052e-06, 4.17308411e-06,\n",
       "         3.73908347e-06, 3.12835482e-06, 3.91784624e-06, 2.77688400e-06,\n",
       "         3.17776176e-06, 2.99907060e-06, 2.74169906e-06, 2.41740554e-06,\n",
       "         2.04516346e-06, 3.10761766e-06, 3.78528784e-06, 2.78568473e-06,\n",
       "         2.95971813e-06, 3.66774225e-06, 2.68122380e-06, 2.52352538e-06,\n",
       "         2.79759593e-06, 1.87942283e-06, 2.80015593e-06, 3.70288080e-06,\n",
       "         3.85395424e-06, 3.81527479e-06, 2.98250779e-06, 3.67615371e-06,\n",
       "         2.94622600e-06, 5.08641460e-06, 3.36380367e-06, 4.03131753e-06,\n",
       "         2.93734934e-06, 2.45198726e-06, 3.05120398e-06, 3.92247784e-06,\n",
       "         3.28658962e-06, 3.55439261e-06, 4.34260755e-06, 1.76869230e-06,\n",
       "         2.61156833e-06, 2.66150028e-06, 3.14651697e-06, 3.28288070e-06,\n",
       "         3.63490199e-06, 2.28644535e-06, 2.81362304e-06, 2.34284903e-06,\n",
       "         2.96956000e-06, 3.23854988e-06, 4.43071804e-06, 2.87829494e-06,\n",
       "         1.75723949e-06, 2.10747135e-06, 4.76188370e-06, 4.07182961e-06,\n",
       "         3.76900994e-06, 3.31632077e-06, 2.17900697e-06, 4.30326327e-06,\n",
       "         3.36245012e-06, 2.99301041e-06, 3.34546871e-06, 3.64027892e-06,\n",
       "         4.02720934e-06, 3.20324739e-06, 3.53313817e-06, 3.12690236e-06,\n",
       "         2.22401081e-06, 2.97663996e-06, 3.69853637e-06, 2.74414492e-06,\n",
       "         3.39724488e-06, 3.11851022e-06, 2.70680516e-06, 3.20560662e-06,\n",
       "         3.21585208e-06, 2.83954409e-06, 3.20935692e-06, 2.34492313e-06,\n",
       "         2.63805214e-06, 3.18463367e-06, 2.84148632e-06, 2.60099978e-06,\n",
       "         2.78168409e-06, 2.48231754e-06, 2.67851465e-06, 2.63840934e-06,\n",
       "         2.42960186e-06, 2.51318602e-06, 3.50220148e-06, 2.89149830e-06,\n",
       "         2.24641235e-06, 3.56912096e-06, 3.77725701e-06, 3.82399867e-06,\n",
       "         1.93651908e-06, 2.74243394e-06, 3.04794116e-06, 3.76039998e-06,\n",
       "         3.15227157e-06, 3.42845760e-06, 2.70159580e-06, 2.45142360e-06,\n",
       "         1.95883604e-06, 2.89545824e-06, 4.96346547e-06, 4.42565670e-06,\n",
       "         2.79518235e-06, 3.56523242e-06, 3.17972308e-06, 3.38072323e-06,\n",
       "         3.63756862e-06, 3.45691956e-06, 3.37602228e-06, 3.62202263e-06,\n",
       "         4.12824784e-06, 3.85642124e-06, 3.35236723e-06, 3.30857165e-06,\n",
       "         2.75680645e-06, 3.99730243e-06, 2.44973648e-06, 2.02926503e-06,\n",
       "         2.99765225e-06, 3.16553587e-06, 4.37578183e-06, 2.59335616e-06,\n",
       "         3.99886221e-06, 3.22897426e-06, 2.42732290e-06, 2.53957774e-06,\n",
       "         3.21820517e-06, 4.76118703e-06, 3.87846603e-06, 2.91230390e-06,\n",
       "         2.69751763e-06, 3.68137762e-06, 3.13263331e-06, 2.70843725e-06,\n",
       "         2.84139446e-06, 2.93877838e-06, 2.78898369e-06, 2.84394264e-06,\n",
       "         5.20021376e-06, 2.30595219e-06, 2.89696072e-06, 4.25206053e-06,\n",
       "         3.61955017e-06, 2.64774826e-06, 2.07651419e-06, 3.59890828e-06,\n",
       "         3.13768624e-06, 2.45180718e-06, 3.43498368e-06, 2.99812677e-06,\n",
       "         2.52081918e-06, 2.70834425e-06, 2.24777523e-06, 2.16727472e-06,\n",
       "         3.31514752e-06, 3.43924148e-06, 3.10721452e-06, 3.83321503e-06,\n",
       "         3.97277836e-06, 3.11076064e-06, 3.34465562e-06, 2.97564657e-06,\n",
       "         3.19596984e-06, 3.25595397e-06, 5.01957493e-06, 3.48497633e-06,\n",
       "         3.70904127e-06, 3.30509943e-06, 2.31666263e-06, 2.33989249e-06,\n",
       "         3.93926166e-06, 1.85413774e-06, 2.47528715e-06, 2.24224073e-06,\n",
       "         2.64398864e-06, 4.07091738e-06, 3.03563547e-06, 2.85384590e-06,\n",
       "         2.62644676e-06, 3.75198556e-06, 3.47879654e-06, 5.35504478e-06,\n",
       "         2.62048479e-06, 3.70084717e-06, 2.00154591e-06, 4.54165092e-06,\n",
       "         2.42065835e-06, 3.38468453e-06, 2.90965545e-06, 4.50875768e-06,\n",
       "         3.44592922e-06, 2.76721607e-06, 2.94201141e-06, 5.02206694e-06,\n",
       "         3.04209834e-06, 2.57062379e-06, 2.47072126e-06, 3.16797923e-06,\n",
       "         3.50031814e-06, 2.12594182e-06, 3.02526018e-06, 3.61472416e-06,\n",
       "         4.04018510e-06, 2.35253879e-06, 2.49295067e-06, 3.85643625e-06,\n",
       "         2.33541596e-06, 2.86372324e-06, 4.00603813e-06, 2.06287723e-06,\n",
       "         3.43874626e-06, 3.45817580e-06, 2.69522661e-06, 4.78175934e-06,\n",
       "         2.22499943e-06, 4.04956245e-06, 3.03101001e-06, 3.05508547e-06,\n",
       "         2.68049507e-06, 3.77904053e-06, 2.86128284e-06, 2.62778485e-06,\n",
       "         2.79654228e-06, 4.11339261e-06, 2.95170435e-06, 2.54420547e-06,\n",
       "         2.60698971e-06, 4.12741701e-06, 4.20532069e-06, 4.00494173e-06,\n",
       "         2.45644833e-06, 3.64727066e-06, 2.98447367e-06, 2.22610311e-06,\n",
       "         3.40311431e-06, 3.72431782e-06, 2.28534668e-06, 3.99972396e-06,\n",
       "         3.76143316e-06, 3.17608328e-06, 2.76166929e-06, 2.49586947e-06,\n",
       "         2.02220781e-06, 2.78586276e-06, 3.45859803e-06, 3.12342422e-06,\n",
       "         3.11704457e-06, 2.65006224e-06, 3.36210360e-06, 2.76004744e-06,\n",
       "         2.35368134e-06, 3.24283656e-06, 3.53488736e-06, 2.04279104e-06,\n",
       "         2.68691133e-06, 2.58671662e-06, 3.84904342e-06, 4.03536751e-06,\n",
       "         2.92789900e-06, 2.62024264e-06, 2.86120098e-06, 2.90783578e-06,\n",
       "         2.50302992e-06, 4.13631096e-06, 2.59382114e-06, 3.69637837e-06,\n",
       "         2.76531409e-06, 3.57612589e-06, 2.77189383e-06, 3.01687328e-06,\n",
       "         2.43752743e-06, 2.85391116e-06, 3.16682508e-06, 2.33076344e-06,\n",
       "         2.00973227e-06, 3.51277822e-06, 2.52144196e-06, 4.43561157e-06,\n",
       "         3.44921386e-06, 2.50654125e-06, 2.52651603e-06, 1.82482097e-06,\n",
       "         2.59260696e-06, 3.50744267e-06, 2.53790472e-06, 3.02120930e-06,\n",
       "         2.26742372e-06, 2.81117696e-06, 3.54898680e-06, 4.72957390e-06,\n",
       "         3.26640065e-06, 1.48256925e-06, 3.74597539e-06, 2.46236141e-06,\n",
       "         2.62524009e-06, 3.85626345e-06, 3.43551437e-06, 2.54843553e-06,\n",
       "         3.76725620e-06, 2.52699328e-06, 3.59825299e-06, 3.44926298e-06,\n",
       "         3.36714152e-06, 2.57588022e-06, 2.51312849e-06, 3.61224306e-06,\n",
       "         3.76903108e-06, 2.96046892e-06, 3.61839739e-06, 3.03034221e-06,\n",
       "         4.34687763e-06, 2.22298854e-06, 4.02308297e-06, 4.05352694e-06,\n",
       "         2.38944244e-06, 2.53919256e-06, 3.36444828e-06, 3.45926765e-06,\n",
       "         2.85350825e-06, 3.55776024e-06, 3.04930745e-06, 3.17752256e-06,\n",
       "         3.36769381e-06, 3.21613106e-06, 2.64615051e-06, 2.90779144e-06,\n",
       "         3.13494343e-06, 5.04414402e-06, 3.05155618e-06, 3.05047683e-06,\n",
       "         2.24711721e-06, 1.95496932e-06, 1.95344660e-06, 4.61316495e-06,\n",
       "         5.18471961e-06, 2.84685962e-06, 2.54310885e-06, 2.44268654e-06,\n",
       "         2.54112092e-06, 3.57137492e-06, 3.74936349e-06, 3.39546364e-06,\n",
       "         2.88391129e-06, 4.26785937e-06, 3.27774046e-06, 2.72046168e-06,\n",
       "         2.40737018e-06, 2.66384404e-06, 3.09095617e-06, 3.16387604e-06,\n",
       "         3.62083802e-06, 2.76559899e-06, 3.52886832e-06, 2.42837632e-06,\n",
       "         2.98138161e-06, 3.15906391e-06, 3.54208896e-06, 4.33338801e-06,\n",
       "         3.36939638e-06, 2.48146307e-06, 3.34659217e-06, 2.93090784e-06,\n",
       "         2.76945502e-06, 4.30862201e-06, 2.91200672e-06, 3.67628013e-06,\n",
       "         2.67351265e-06, 3.51888752e-06, 3.47078048e-06, 3.39091048e-06,\n",
       "         6.62645152e-06, 4.66113352e-06, 2.94314236e-06, 3.33090725e-06,\n",
       "         2.51522897e-06, 2.18441869e-06, 3.60398803e-06, 2.57135184e-06,\n",
       "         2.56399107e-06, 3.31874412e-06, 4.76424111e-06, 2.30245837e-06,\n",
       "         3.70616658e-06, 3.76130038e-06, 2.80945096e-06, 3.89846900e-06,\n",
       "         2.65791869e-06, 2.81500797e-06, 2.51761912e-06, 3.09417692e-06,\n",
       "         3.53913083e-06, 1.98913881e-06, 3.36222888e-06, 3.47239620e-06,\n",
       "         2.73783212e-06, 2.61553896e-06, 3.17523518e-06, 4.10737948e-06,\n",
       "         2.90550179e-06, 3.52486609e-06, 2.97672523e-06, 2.47322464e-06,\n",
       "         1.70313433e-06, 3.05994922e-06, 2.26998759e-06, 3.59921069e-06,\n",
       "         4.06854997e-06, 2.77475033e-06, 2.96359622e-06, 3.94910512e-06,\n",
       "         3.39833377e-06, 3.33349703e-06, 3.20658523e-06, 2.89232025e-06,\n",
       "         4.16945204e-06, 2.56389558e-06, 2.63438915e-06, 2.25099734e-06,\n",
       "         3.56543660e-06, 2.21583218e-06, 3.04748187e-06, 3.79496419e-06,\n",
       "         2.89760715e-06, 3.32132481e-06, 2.30124419e-06, 3.79297762e-06,\n",
       "         2.81549933e-06, 3.86966894e-06, 3.66650784e-06, 3.38128416e-06,\n",
       "         3.47992841e-06, 3.18003231e-06, 4.20309107e-06, 3.65732308e-06,\n",
       "         2.62141725e-06, 3.61020761e-06, 2.91754964e-06, 4.10511984e-06,\n",
       "         2.95461655e-06, 2.72933607e-06, 2.68978033e-06, 3.33403455e-06,\n",
       "         2.31946797e-06, 3.36481730e-06, 3.61238426e-06, 3.99936152e-06,\n",
       "         3.11092094e-06, 2.76565697e-06, 2.60377692e-06, 3.51693825e-06,\n",
       "         3.06241304e-06, 1.91628283e-06, 2.83961458e-06, 2.95143423e-06,\n",
       "         3.98190059e-06, 2.84205021e-06, 4.73974660e-06, 3.31393062e-06,\n",
       "         2.65714061e-06, 3.06103789e-06, 4.16282091e-06, 3.54945041e-06,\n",
       "         4.07266862e-06, 3.32599029e-06, 2.93694870e-06, 4.62797288e-06,\n",
       "         2.33763080e-06, 2.53870348e-06, 2.39627911e-06, 4.34980484e-06,\n",
       "         2.62755430e-06, 3.21619268e-06, 2.69457360e-06, 3.34383230e-06,\n",
       "         3.87274849e-06, 3.00941929e-06, 3.16087539e-06, 4.83237909e-06,\n",
       "         2.56097542e-06, 3.59203364e-06, 3.28701890e-06, 3.58601642e-06,\n",
       "         2.15828186e-06, 3.05091021e-06, 5.39742314e-06, 3.49985089e-06,\n",
       "         3.04855143e-06, 3.54573535e-06, 3.13457554e-06, 2.87848457e-06,\n",
       "         3.65176425e-06, 4.31104127e-06, 2.96171447e-06, 3.15085913e-06,\n",
       "         2.89059108e-06, 3.90645573e-06, 5.03915817e-06, 2.73546220e-06,\n",
       "         2.66542202e-06, 2.22318363e-06, 2.49056234e-06, 2.92635536e-06,\n",
       "         2.86490604e-06, 2.62017761e-06, 3.33281992e-06, 2.52145878e-06,\n",
       "         3.94485187e-06, 4.84133989e-06, 2.48941546e-06, 3.19078936e-06,\n",
       "         3.05748995e-06, 2.63905622e-06, 3.89852448e-06, 3.27212501e-06,\n",
       "         2.95571294e-06, 2.95271798e-06, 3.86792772e-06, 2.28245631e-06,\n",
       "         2.74905096e-06, 4.09136646e-06, 3.68447536e-06, 2.47737012e-06,\n",
       "         2.14534134e-06, 3.38233872e-06, 3.86682495e-06, 3.39683015e-06,\n",
       "         2.44353214e-06, 2.99382395e-06, 3.15803391e-06, 3.82161124e-06,\n",
       "         2.97785232e-06, 3.55704765e-06, 2.75484308e-06, 3.53593941e-06,\n",
       "         3.18011439e-06, 2.97765064e-06, 2.90310595e-06, 2.58063073e-06,\n",
       "         2.51323377e-06, 2.82231940e-06, 3.67610824e-06, 2.67511177e-06,\n",
       "         4.15149407e-06, 2.15412615e-06, 2.96499275e-06, 2.71699764e-06,\n",
       "         2.04203320e-06, 4.77648564e-06, 3.69801432e-06, 2.44789157e-06,\n",
       "         2.53870348e-06, 3.29983050e-06, 3.63842582e-06, 3.76717344e-06,\n",
       "         2.64233995e-06, 2.14628062e-06, 3.92069023e-06, 3.76264234e-06,\n",
       "         3.47784476e-06, 3.11268377e-06, 3.94476137e-06, 2.35655170e-06,\n",
       "         2.83080794e-06, 2.87975581e-06, 2.94611914e-06, 4.10407847e-06,\n",
       "         3.89479328e-06, 3.85458634e-06, 2.39173141e-06, 3.24633925e-06]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj =vgg16_in()\n",
    "obj.loadWeights()\n",
    "obj.make_partition()\n",
    "obj.execute_full_network()\n",
    "obj.execute_full_partition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.getsizeof(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def use_layer(layer):\n",
    "#     print(type(layer))\n",
    "#     print(sys.getsizeof(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1=obj.get_layer(0)\n",
    "\n",
    "# print(type(layer1))\n",
    "# inp=np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "\n",
    "# op1=obj.execute_on_core(0,inp)\n",
    "# op2=layer1(inp)\n",
    "# # use_layer(layer1)\n",
    "# # print(op1)\n",
    "# print('===================================================')\n",
    "# # print(op2)\n",
    "# equal_result = tf.equal(op1, op2)\n",
    "# print(equal_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_input = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "INPUT_LIST=[]\n",
    "INPUT_LIST.append(random_input)\n",
    "for i in range(1,NO_OF_LAYER):\n",
    "    tmp=obj.execute_on_core(i-1,INPUT_LIST[i-1])\n",
    "    INPUT_LIST.append(tmp)\n",
    "    \n",
    "len(INPUT_LIST[20][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lays=[13,14]\n",
    "inp_seq=INPUT_LIST[13:15]\n",
    "# inp_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_13 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 112, 112, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conn_list=[13,14,16,17,18,19]\n",
    "# conn_list=[20]\n",
    "obj.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_profiling(obj,layers,inp_seq):\n",
    "\n",
    "    NO_EXP=10\n",
    "    main_readings=[]\n",
    "\n",
    "    # tag=f'lay{conn+1}{conn+2}'\n",
    "\n",
    "    for i in range(NO_EXP):\n",
    "        res=perform_grid(obj,layers,inp_seq)\n",
    "        main_readings.append(res)\n",
    "        csv_name=f'./reads/conn/vgg16_lay_{layers[0]}_to_{layers[1]}_r{i+1}.csv'\n",
    "        heat_map_name=f'heat_map_vgg16_lay_{layers[0]}_to_{layers[1]}_r{i+1}'\n",
    "        write_to_csv(csv_name,res)\n",
    "        make_heatmap(res,heat_map_name)\n",
    "        \n",
    "        \n",
    "    result_ave = np.mean(main_readings, axis=0)\n",
    "    result_ave\n",
    "\n",
    "    avcsv_name=f'./reads/conn/ave_reads_lay_{layers[0]}_to_{layers[1]}.csv'\n",
    "\n",
    "    write_to_csv(avcsv_name,result_ave)\n",
    "    avf_name=f'ave_reads_lay{layers[0]}_to_{layers[1]}'\n",
    "    make_heatmap(result_ave,avf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for 4 seconds\n",
      "Sleeping for 4 seconds\n",
      "Sleeping for 4 seconds\n",
      "Sleeping for 4 seconds\n",
      "Sleeping for 4 seconds\n",
      "Sleeping for 4 seconds\n"
     ]
    }
   ],
   "source": [
    "for ele in conn_list:\n",
    "    layers=[ele,ele+1]\n",
    "    inp_da=[INPUT_LIST[ele],INPUT_LIST[ele+1]]\n",
    "    do_profiling(obj=obj,layers=layers,inp_seq=inp_da)\n",
    "    print('Sleeping for 4 seconds')\n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnpart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
