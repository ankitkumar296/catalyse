{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import psutil\n",
    "import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class pilotnet():\n",
    "    def __init__(self) -> None:\n",
    "        self.weight_set=False\n",
    "        self.partition_done=False\n",
    "        self.input_loaded=False\n",
    "        self.layer_list=[]\n",
    "        \n",
    "        self.model = models.Sequential()\n",
    "        # # Normalization layer\n",
    "        self.model.add(layers.LayerNormalization(center=True , scale=True,input_shape=(66,200, 3)))\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.model.add(layers.Conv2D(24, (5, 5), strides=(2, 2), activation='relu'))\n",
    "        self.model.add(layers.Conv2D(36, (5, 5), strides=(2, 2), activation='relu'))\n",
    "        self.model.add(layers.Conv2D(48, (5, 5), strides=(2, 2), activation='relu'))\n",
    "        self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "        # Flatten layer\n",
    "        self.model.add(layers.Flatten())\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.model.add(layers.Dense(100, activation='relu'))\n",
    "        self.model.add(layers.Dense(50, activation='relu'))\n",
    "        self.model.add(layers.Dense(10, activation='relu'))\n",
    "        \n",
    "        # Output layer\n",
    "        self.model.add(layers.Dense(1))  # Output: steering angle\n",
    "        self.model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "       \n",
    "        #install \"pip install pydot-ng\"  and \"apt install graphviz\" for ploting below model\n",
    "        tf.keras.utils.plot_model(self.model, to_file='pilotnet_model.png', show_shapes=True)\n",
    "        \n",
    "        # return self.model\n",
    "        \n",
    "    def loadWeights(self):\n",
    "        self.model.load_weights('./pilotnet_model.h5')\n",
    "        # model = load_model('model.h5')\n",
    "        self.weight_set=True\n",
    "        print(\"\\_____Weights are loaded to the \")\n",
    "        \n",
    "    def model_info(self):\n",
    "        self.no_of_layers=len(self.model.layers)\n",
    "        print(\"\\_____Number of Layers in Model: \",self.no_of_layers)\n",
    "        print(\"\\_____Weights are loaded: \",self.weight_set)\n",
    "        print(\"\\_____Input loaded to Model: \",self.input_loaded)\n",
    "        print('\\_____Partitioning Done: ',self.partition_done)\n",
    "        \n",
    "    def load_input(self):\n",
    "        self.input_data = np.random.rand(1, 66, 200, 3).astype(np.float32)\n",
    "        self.input_loaded=True\n",
    "        return self.input_data\n",
    "        \n",
    "    def make_partition(self):\n",
    "        self.NO_OF_LAYERS= len(self.model.layers)\n",
    "        \n",
    "        for i in range(self.NO_OF_LAYERS):\n",
    "            self.temp_layer=self.model.layers[i]\n",
    "            self.layer_list.append(self.temp_layer)\n",
    "            \n",
    "        self.partition_done = True\n",
    "        print('\\_______Partitioning Done')\n",
    "\n",
    "    \n",
    "    def save_pickeled_layers(self):\n",
    "        if not self.weight_set:\n",
    "            self.loadWeights()\n",
    "\n",
    "        \n",
    "        if not self.partition_done:\n",
    "            self.make_partition()\n",
    "        save_dir='pilotnet_pickle'\n",
    "        for i in range(len(self.layer_list)):\n",
    "            fname=f'./{save_dir}/pilotnet_layer_{i}.pkl'\n",
    "            layer_weights_and_config = {\n",
    "                'weights': self.layer_list[i].get_weights(),\n",
    "                'config': tf.keras.layers.serialize(self.layer_list[i])}\n",
    "            with open(fname, 'wb') as f:\n",
    "                pickle.dump(layer_weights_and_config, f)\n",
    "    \n",
    "    def execute_full_network(self):\n",
    "        if not self.input_loaded:\n",
    "            self.load_input()\n",
    "        print(\"I am in full Executioon\")\n",
    "        st1=time.perf_counter()\n",
    "        self.output=self.model.predict(self.input_data)\n",
    "        ed1=time.perf_counter()\n",
    "        \n",
    "        elt1=ed1-st1\n",
    "        elt1=float(elt1)\n",
    "        return elt1,self.output\n",
    "        \n",
    "    def execute_full_network_sample(self,imp):\n",
    "        st1=time.perf_counter()        \n",
    "        self.output=self.model.predict(imp)\n",
    "        ed1=time.perf_counter()\n",
    "        \n",
    "        elt1=ed1-st1\n",
    "        elt1=float(elt1)        \n",
    "        return elt1\n",
    "    \n",
    "    def execute_full_partition(self):\n",
    "        if not self.partition_done:\n",
    "            self.make_partition()\n",
    "        if not self.input_loaded:\n",
    "            self.load_input()\n",
    "            \n",
    "        self.temp_res=self.input_data\n",
    "        st2=time.perf_counter()\n",
    "        for i in range(self.NO_OF_LAYERS):\n",
    "            self.temp_res = self.layer_list[i](self.temp_res)\n",
    "        ed2=time.perf_counter()\n",
    "        self.temp_res=np.array(self.temp_res)\n",
    "        elt2=ed2-st2\n",
    "        elt2=float(elt2)\n",
    "        \n",
    "        return elt2,self.temp_res\n",
    "    \n",
    "    def execute_layer_by_layer_sample(self,inp):\n",
    "        temp_out=inp\n",
    "        for lay in self.layer_list:\n",
    "            \n",
    "            temp_out=lay(temp_out)\n",
    "               \n",
    "        temp_out=np.array(temp_out)\n",
    "                    \n",
    "        return temp_out\n",
    "    \n",
    "    def execute_on_core(self,layer_id,input_data):\n",
    "                \n",
    "        self.temp_out=self.layer_list[layer_id](input_data)\n",
    "        \n",
    "        return self.temp_out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_d=np.zeros(shape=(1,66, 200,3)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankit/anaconda3/envs/nnsc/lib/python3.11/site-packages/keras/src/layers/normalization/layer_normalization.py:122: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\_____Weights are loaded to the \n",
      "\\_____Number of Layers in Model:  11\n",
      "\\_____Weights are loaded:  True\n",
      "\\_____Input loaded to Model:  False\n",
      "\\_____Partitioning Done:  False\n",
      "\\_______Partitioning Done\n",
      "I am in full Executioon\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Time required : 0.08076475799998661 result : \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# try:\n",
    "#     psutil.Process().cpu_affinity([121])\n",
    "# except AttributeError:\n",
    "#     pass \n",
    "\n",
    "# obj =vgg16_in()\n",
    "# obj.loadWeights()\n",
    "# obj.model_info()\n",
    "obj=pilotnet()\n",
    "obj.loadWeights()\n",
    "obj.model_info()\n",
    "obj.make_partition()\n",
    "res1=obj.execute_full_network()\n",
    "# res2 = obj.execute_full_partition()\n",
    "print(f'Time required : {res1[0]} result : ')\n",
    "# print(f'Time required : {res2[0]} result : ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\_____Number of Layers in Model:  11\n",
      "\\_____Weights are loaded:  True\n",
      "\\_____Input loaded to Model:  True\n",
      "\\_____Partitioning Done:  True\n"
     ]
    }
   ],
   "source": [
    "obj.model_info()\n",
    "obj.save_pickeled_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
