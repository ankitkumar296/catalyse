{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 22:31:50.793447: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-04 22:31:50.795712: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-04 22:31:50.823323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-04 22:31:51.306464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import psutil\n",
    "import csv\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_driving_mtl():\n",
    "    def __init__(self) -> None:\n",
    "            \n",
    "        input_shape = (140, 208, 3)\n",
    "\n",
    "        # Create input layer\n",
    "        inputs = layers.Input(shape=input_shape ,name='0_input_layer')\n",
    "\n",
    "        # Backbone network\n",
    "        backbone_output = self.backbone_network(inputs)\n",
    "        \n",
    "        classification_output = self.classification_branch(backbone_output)\n",
    "\n",
    "        # Detection branch\n",
    "        detection_output = self.detection_branch(backbone_output)\n",
    "\n",
    "        # Create model\n",
    "        self.model = models.Model(inputs=inputs, outputs=[classification_output, detection_output])\n",
    "\n",
    "        # Print model summary\n",
    "        # print(self.model.summary())\n",
    "\n",
    "    \n",
    "    def backbone_network(self,inputs):\n",
    "        x = layers.Conv2D(24, (12, 12), activation='relu', strides=2, padding='valid',name='1_conv2D_1')(inputs)\n",
    "        x = layers.Conv2D(36, (8, 8), activation='relu', strides=2, padding='valid' ,name='2_conv2D_2')(x)\n",
    "        x = layers.Conv2D(48, (8, 8), activation='relu', strides=2, padding='valid' ,name='3_conv2D_2')(x)\n",
    "        x = layers.Dropout(0.5 ,name='4_dropout')(x)\n",
    "        x = layers.Conv2D(64, (5, 5), activation='relu', padding='valid', dilation_rate=2 ,name='5_conv2D_4')(x)\n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='valid' ,name='6_conv2D_5')(x)\n",
    "        x = layers.Flatten(name='7_flatten')(x)\n",
    "        return x\n",
    "    \n",
    "    def classification_branch(self,backbone_output):\n",
    "        x = layers.Dense(100, activation='relu',name='8_dense_12')(backbone_output)\n",
    "        x = layers.Dense(50, activation='relu' ,name='10_dense_13')(x)\n",
    "        x = layers.Dense(10, activation='relu' ,name='12_dense_14')(x)\n",
    "        x = layers.Dense(1, activation='relu' ,name='14_dense_15')(x)\n",
    "        outputs = layers.Activation( activation='relu',  name='yaw_rate')(x)\n",
    "        return outputs\n",
    "    \n",
    "    def detection_branch(self,backbone_output):\n",
    "        x = layers.Dense(100, activation='relu' ,name='9_dense_22')(backbone_output)\n",
    "        x = layers.Dense(50, activation='relu' ,name='11_dense_23')(x)\n",
    "        x = layers.Dense(10, activation='relu' ,name='13_dense_24')(x)\n",
    "        x = layers.Dense(1, activation='relu' ,name='15_dense_25')(x)\n",
    "        outputs = layers.Activation( activation='relu', name='speed')(x)\n",
    "        return outputs\n",
    "\n",
    "    def load_weights(self):\n",
    "        self.model.load_weights('./self_driving_mtl_model.h5')\n",
    "    \n",
    "    def print_layers(self):\n",
    "        # self.layer_list=[]\n",
    "        \n",
    "        for lay in self.model.layers:\n",
    "            print(lay.name)\n",
    "            # self.layer_list.append(lay)\n",
    "    \n",
    "    def execute_lbl(self,input_data):\n",
    "        st2=time.perf_counter()\n",
    "        out=buffer=input_data\n",
    "        for idx in range(1,len(self.model.layers)):\n",
    "            # print(f'Executing: {self.model.layers[idx]}')\n",
    "            if idx <= 7:\n",
    "                out=buffer=self.model.layers[idx](out)\n",
    "            elif idx in [8,10,12,14,16]:\n",
    "                out=self.model.layers[idx](out)\n",
    "            elif idx in [9,11,13,15,17]:\n",
    "                buffer=self.model.layers[idx](buffer)\n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(f'Elapsed Time: {el2}')\n",
    "        return out,buffer\n",
    "    \n",
    "    def make_partition(self):\n",
    "        self.layer_list=[]\n",
    "        self.NO_OF_LAYERS= len(self.model.layers)\n",
    "        \n",
    "        for i in range(self.NO_OF_LAYERS):\n",
    "            self.temp_layer=self.model.layers[i]\n",
    "            self.layer_list.append(self.temp_layer)\n",
    "            \n",
    "        self.partition_done = True\n",
    "    \n",
    "    def save_pickeled_layers(self):\n",
    "        # if not self.weight_set:\n",
    "        self.load_weights()\n",
    "\n",
    "        \n",
    "        # if not self.partition_done:\n",
    "        self.make_partition()\n",
    "        save_dir='../pickle_layers'\n",
    "        for i in range(len(self.layer_list)):\n",
    "            fname=f'./{save_dir}/self_driving_mtl_layer_{i}.pkl'\n",
    "            layer_weights_and_config = {\n",
    "                'weights': self.layer_list[i].get_weights(),\n",
    "                'config': tf.keras.layers.serialize(self.layer_list[i])}\n",
    "            with open(fname, 'wb') as f:\n",
    "                pickle.dump(layer_weights_and_config, f)\n",
    "                \n",
    "    def get_input_list(self,input_data):\n",
    "        self.input_list=[]\n",
    "        st2=time.perf_counter()\n",
    "        out=buffer=input_data\n",
    "        self.input_list.append(input_data)\n",
    "        for idx in range(1,len(self.model.layers)):\n",
    "            # print(f'Executing index {idx} :  {self.model.layers[idx]}')\n",
    "            if idx <= 7:\n",
    "                self.input_list.append(out)\n",
    "                out=buffer=self.model.layers[idx](out)\n",
    "            elif idx in [8,10,12,14,16]:\n",
    "                self.input_list.append(out)\n",
    "                out=self.model.layers[idx](out)\n",
    "            elif idx in [9,11,13,15,17]:\n",
    "                self.input_list.append(buffer)\n",
    "                buffer=self.model.layers[idx](buffer)\n",
    "        et2=time.perf_counter()\n",
    "        el2=et2-st2\n",
    "        print(f'Elapsed Time: {el2}')\n",
    "        return self.input_list\n",
    "    \n",
    "    def execute_on_core(self,layer_id,input_data,dummy_data):\n",
    "        dummy_data=dummy_data\n",
    "        # print(self.layer_list[layer_id].name)\n",
    "        self.temp_out=self.layer_list[layer_id](input_data)\n",
    "        \n",
    "        return self.temp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_execution_time(target_instance, target_method, core_id=0, *args):\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id])\n",
    "    except AttributeError:\n",
    "        pass  \n",
    "    start_time = time.perf_counter()\n",
    "    tt=getattr(target_instance, target_method)(*args)\n",
    "    end_time = time.perf_counter()\n",
    "    execution_time = end_time - start_time\n",
    "    # print(f\"Execution time on core {core_id}: {execution_time} seconds\")\n",
    "    return execution_time,tt\n",
    "\n",
    "def compute_pair_execution_time(target_instance, target_method, core_id=[0,0], *args):\n",
    "    \n",
    "    st1=time.perf_counter()\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id[0]])\n",
    "    except AttributeError:\n",
    "        pass  \n",
    "    et1=time.perf_counter()\n",
    "    layer=args[0]\n",
    "    inp_seq=args[1]\n",
    "    st2 = time.perf_counter()\n",
    "    tt=getattr(target_instance, target_method)(layer[0],inp_seq[0],'dum')\n",
    "    et2 = time.perf_counter()\n",
    "    \n",
    "    st3=time.perf_counter()\n",
    "    try:\n",
    "        psutil.Process().cpu_affinity([core_id[1]])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    et3=time.perf_counter()\n",
    "    st4=time.perf_counter()\n",
    "    tt2=getattr(target_instance, target_method)(layer[1],inp_seq[1],tt)\n",
    "    et4 = time.perf_counter()\n",
    "    \n",
    "    el1=et4-st1\n",
    "    el2=et2-st2\n",
    "    el3=et3-st3\n",
    "    el4=et4-st4\n",
    "    execution_time = el1+el2+el3+el4\n",
    "    # print(f\"Execution time on core {core_id}: {execution_time} seconds\")\n",
    "    return el1,tt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_LAYERS=18\n",
    "NO_OF_CPU=24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_grid(obj,layer_ids,core_ids,input_data):\n",
    "    # temp=[0]*2\n",
    "    temp_out=input_data\n",
    "    # st=time.perf_counter()\n",
    "    # for lay in range(len(layer_ids)):\n",
    "    temp,temp_out=compute_pair_execution_time(obj,'execute_on_core',core_ids,layer_ids,temp_out)  \n",
    "        \n",
    "    # et=time.perf_counter()\n",
    "    # el=et-st\n",
    "    return temp, temp\n",
    "    \n",
    "\n",
    "def perform_grid(obj,lays,inp_seq):\n",
    "    res=np.zeros((NO_OF_CPU,NO_OF_CPU),dtype =  float)\n",
    "    for i in range(NO_OF_CPU):\n",
    "        for j in range(NO_OF_CPU):\n",
    "            #Now schedule this function on the CPU-0 to run the two layers on the different CPUs\n",
    "            # temp,res[i][j]= compute_execution_time_of_function(try_grid,0,obj,lays,[i,j],inp_seq)\n",
    "            # st=time.perf_counter()\n",
    "            res[i][j],temp=try_grid(obj,lays,[i,j],inp_seq)\n",
    "            \n",
    "            # et=time.perf_counter()\n",
    "            # el=et-st\n",
    "            # res[i][j]=el\n",
    "        time.sleep(0.5)\n",
    "    return res\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap(readings,name):\n",
    "    plt.imshow(readings, cmap='cividis', interpolation='nearest')\n",
    "    path='./img/conn/'+name+'.png'\n",
    "    plt.colorbar()\n",
    "    plt.title(name)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def write_to_csv(name,res):\n",
    "    csv_file_path=name\n",
    "    row_headings =[str(i) for i in range(24)]\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(row_headings)\n",
    "        # Write each row of the array to the CSV file\n",
    "        for row in res:\n",
    "            \n",
    "            csv_writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_profiling(obj,layers,inp_seq):\n",
    "\n",
    "    NO_EXP=10\n",
    "    main_readings=[]\n",
    "\n",
    "    # tag=f'lay{conn+1}{conn+2}'\n",
    "\n",
    "    for i in range(NO_EXP):\n",
    "        res=perform_grid(obj,layers,inp_seq)\n",
    "        main_readings.append(res)\n",
    "        csv_name=f'./readings/conn/self_drive_mtl_lay_{layers[0]}_to_{layers[1]}_r{i+1}.csv'\n",
    "        heat_map_name=f'heat_map_self_drive_mtl_lay_{layers[0]}_to_{layers[1]}_r{i+1}'\n",
    "        write_to_csv(csv_name,res)\n",
    "        make_heatmap(res,heat_map_name)\n",
    "        gc.collect()\n",
    "        time.sleep(0.5)\n",
    "        gc.collect()\n",
    "        \n",
    "    \n",
    "    result_ave = np.mean(main_readings, axis=0)\n",
    "    result_ave\n",
    "\n",
    "    avcsv_name=f'./readings/conn/ave_reads_lay_{layers[0]}_to_{layers[1]}.csv'\n",
    "\n",
    "    write_to_csv(avcsv_name,result_ave)\n",
    "    avf_name=f'ave_reads_lay{layers[0]}_to_{layers[1]}'\n",
    "    make_heatmap(result_ave,avf_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(num_list):\n",
    "\n",
    "    if not num_list:\n",
    "        return None  # Return None if the list is empty\n",
    "\n",
    "    total = sum(num_list)  # Calculate the sum of all numbers in the list\n",
    "    mean = total / len(num_list)  # Calculate the mean by dividing the sum by the number of elements\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_list=[[2,3],[6,7],[7,8],[8,10],[14,16]]\n",
    "# conn_list=[[2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= np.random.rand(1, 140,208,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.008787360013229772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[43.224335]], dtype=float32)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj=self_driving_mtl()\n",
    "obj.load_weights()\n",
    "obj.make_partition()\n",
    "# obj.print_layers()\n",
    "# obj.save_pickeled_layers()\n",
    "obj.execute_lbl(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.01678914498188533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_LIST=obj.get_input_list(image)\n",
    "len(INPUT_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[43.224335]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,18):\n",
    "    out=obj.execute_on_core (j,INPUT_LIST[j],f'{j}')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROFILING for Layer [2, 3]\n",
      "Sleeping for 4 seconds\n"
     ]
    }
   ],
   "source": [
    "for ele in conn_list:\n",
    "    print(f'PROFILING for Layer {ele}')\n",
    "    layers=[ele[0],ele[1]]\n",
    "    inp_da=[INPUT_LIST[ele[0]],INPUT_LIST[ele[1]]]\n",
    "    do_profiling(obj=obj,layers=layers,inp_seq=inp_da)\n",
    "    print('Sleeping for 4 seconds')\n",
    "    gc.collect()\n",
    "    time.sleep(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
